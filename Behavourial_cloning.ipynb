{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "44xomqeXOat9",
        "outputId": "11469c93-fe78-4cb6-ee67-9aa2902f0396"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/100], Loss: 0.0454\n",
            "Epoch [20/100], Loss: 0.0117\n",
            "Epoch [30/100], Loss: 0.0059\n",
            "Epoch [40/100], Loss: 0.0056\n",
            "Epoch [50/100], Loss: 0.0034\n",
            "Epoch [60/100], Loss: 0.0020\n",
            "Epoch [70/100], Loss: 0.0013\n",
            "Epoch [80/100], Loss: 0.0007\n",
            "Epoch [90/100], Loss: 0.0003\n",
            "Epoch [100/100], Loss: 0.0001\n",
            "Action: tensor([[0.3918, 0.4627]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "class BehaviorCloneAgent(nn.Module):\n",
        "    def __init__(self, input_size, output_size):\n",
        "        super(BehaviorCloneAgent, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, 64)\n",
        "        self.fc2 = nn.Linear(64, output_size)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "def train_behavior_clone_agent(expert_data, num_epochs):\n",
        "    # Prepare expert data\n",
        "    expert_states, expert_actions = expert_data\n",
        "\n",
        "    # Define agent and loss function\n",
        "    input_size = expert_states.shape[1]\n",
        "    output_size = expert_actions.shape[1]\n",
        "    agent = BehaviorCloneAgent(input_size, output_size)\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = optim.Adam(agent.parameters(), lr=0.001)\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(num_epochs):\n",
        "        optimizer.zero_grad()\n",
        "        outputs = agent(expert_states)\n",
        "        loss = criterion(outputs, expert_actions)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if (epoch+1) % 10 == 0:\n",
        "            print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, loss.item()))\n",
        "\n",
        "    return agent\n",
        "\n",
        "# Usage example\n",
        "expert_states = torch.tensor([[0.1, 0.2, 0.3],\n",
        "                              [0.4, 0.5, 0.6],\n",
        "                              [0.7, 0.8, 0.9]])\n",
        "expert_actions = torch.tensor([[0.3, 0.4],\n",
        "                               [0.5, 0.6],\n",
        "                               [0.7, 0.8]])\n",
        "\n",
        "num_epochs = 100\n",
        "agent = train_behavior_clone_agent((expert_states, expert_actions), num_epochs)\n",
        "\n",
        "# Test the trained agent\n",
        "test_state = torch.tensor([[0.2, 0.3, 0.4]])\n",
        "action = agent(test_state)\n",
        "print('Action:', action)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#First, we define a PyTorch module called BehaviorCloneAgent that represents the neural network model used by each agent. It has two fully connected layers with a ReLU activation function.\n",
        "\n",
        "The train_behavior_clone_agent function takes expert data (states and corresponding actions) and the number of training epochs as input.\n",
        "\n",
        "Inside train_behavior_clone_agent, we create an instance of the BehaviorCloneAgent class, specifying the input size (determined by the number of features in the state) and output size (determined by the number of actions).\n",
        "\n",
        "We define the loss function (nn.MSELoss) and the optimizer (optim.Adam) that will be used for training the agent. The optimizer is responsible for updating the agent's parameters based on the calculated gradients.\n",
        "\n",
        "The training loop begins, iterating for the specified number of epochs. In each epoch:\n",
        "\n",
        "The gradients accumulated from the previous iteration are reset to zero using optimizer.zero_grad().\n",
        "The agent is passed the expert states as input, and the predicted actions are obtained using agent(expert_states).\n",
        "The loss between the predicted actions and expert actions is calculated using the mean squared error (criterion(outputs, expert_actions)).\n",
        "The gradients of the loss with respect to the agent's parameters are computed using backpropagation (loss.backward()).\n",
        "The optimizer updates the agent's parameters based on the computed gradients (optimizer.step()).\n",
        "During training, the loss is printed every 10 epochs to monitor the training progress.\n",
        "\n",
        "Once the training loop is completed, the trained agent is returned from the train_behavior_clone_agent function.\n",
        "\n",
        "In the usage example, we provide some expert data (expert_states and expert_actions) and the number of training epochs (num_epochs).\n",
        "\n",
        "The train_behavior_clone_agent function is called with the expert data and number of epochs to train the agent.\n",
        "\n",
        "After training, we can test the trained agent by providing a test state (test_state). The trained agent predicts the corresponding action for the test state using agent(test_state).\n",
        "\n",
        "Finally, the predicted action is printed."
      ],
      "metadata": {
        "id": "6c2Jkg77O8bX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "class BehaviorCloneAgent(nn.Module):\n",
        "    def __init__(self, input_size, output_size):\n",
        "        super(BehaviorCloneAgent, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, 64)\n",
        "        self.fc2 = nn.Linear(64, output_size)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "def train_behavior_clone_agent(expert_data, num_epochs):\n",
        "    # Prepare expert data\n",
        "    expert_states, expert_actions = expert_data\n",
        "\n",
        "    # Define agent and loss function\n",
        "    input_size = expert_states.shape[1]\n",
        "    output_size = expert_actions.shape[1]\n",
        "    agent = BehaviorCloneAgent(input_size, output_size)\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = optim.Adam(agent.parameters(), lr=0.001)\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(num_epochs):\n",
        "        optimizer.zero_grad()\n",
        "        outputs = agent(expert_states)\n",
        "        loss = criterion(outputs, expert_actions)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if (epoch+1) % 10 == 0:\n",
        "            print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, loss.item()))\n",
        "\n",
        "    return agent\n",
        "\n",
        "# Usage example\n",
        "expert_states = torch.tensor([[0.1, 0.2, 0.3],\n",
        "                              [0.4, 0.5, 0.6],\n",
        "                              [0.7, 0.8, 0.9]])\n",
        "expert_actions = torch.tensor([[0.3, 0.4],\n",
        "                               [0.5, 0.6],\n",
        "                               [0.7, 0.8]])\n",
        "\n",
        "num_epochs = 100\n",
        "agent = train_behavior_clone_agent((expert_states, expert_actions), num_epochs)\n",
        "\n",
        "# Test the trained agent\n",
        "test_state = torch.tensor([[0.2, 0.3, 0.4]])\n",
        "action = agent(test_state)\n",
        "print('Action:', action)\n",
        "\n"
      ],
      "metadata": {
        "id": "qo-s4MgPXYdF",
        "outputId": "6c9f4021-2b96-480d-d0e3-3f2ca1e717aa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/100], Loss: 0.0871\n",
            "Epoch [20/100], Loss: 0.0342\n",
            "Epoch [30/100], Loss: 0.0105\n",
            "Epoch [40/100], Loss: 0.0043\n",
            "Epoch [50/100], Loss: 0.0033\n",
            "Epoch [60/100], Loss: 0.0025\n",
            "Epoch [70/100], Loss: 0.0016\n",
            "Epoch [80/100], Loss: 0.0011\n",
            "Epoch [90/100], Loss: 0.0008\n",
            "Epoch [100/100], Loss: 0.0005\n",
            "Action: tensor([[0.3870, 0.4768]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7XvgslukXav2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}